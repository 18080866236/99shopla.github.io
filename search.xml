<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Adobe PhotoShop 最新（beta） Firefly AI 功能</title>
      <link href="/posts/97ca.html"/>
      <url>/posts/97ca.html</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><img src="https://img.99shopla.com/photoshopbata.png" alt="adobe photoshop bata.png"></p><p>CreativeCloud 最新安裝包：【**<a href="https://creativecloud.adobe.com/apps/download/creative-cloud">点击下载</a>**】</p><p><strong>【注意】：注册的时候请选择美国地区，大陆地区请用美国ip，就无需绑卡。</strong></p><p>如果登录的大陆地区账号，在Adobe Creative Cloud裡面先注销账号，如果没有美国地区账号，点击注册新账号，用任意邮箱注册，地区填写美国(特别重要)，使用注册的新账号登录Adobe Creative Cloud即可。</p><p>目前AI创成式填充工具国内账号经常出现系统繁忙或者生成图像出错，尽量用挂国外IP使用，国外IP使用正常，没有一次生成图像失败。</p>]]></content>
      
      
      <categories>
          
          <category> 免费资源 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AI绘画 </tag>
            
            <tag> PS </tag>
            
            <tag> 免费资源 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SD WEBUI 常见错误汇总</title>
      <link href="/posts/2882.html"/>
      <url>/posts/2882.html</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="收集的一些运行SDWEBUI常见错误汇总"><a href="#收集的一些运行SDWEBUI常见错误汇总" class="headerlink" title="收集的一些运行SDWEBUI常见错误汇总"></a>收集的一些运行SDWEBUI常见错误汇总</h1><h2 id="启动SD-WebUI时产生错误-无找到启动所需的Git-组件"><a href="#启动SD-WebUI时产生错误-无找到启动所需的Git-组件" class="headerlink" title="启动SD-WebUI时产生错误:+无找到启动所需的Git+组件"></a>启动SD-WebUI时产生错误:+无找到启动所需的Git+组件</h2><p>这个错误提示通常是由于缺少Git组件导致的。您可以按照以下步骤来解决此问题：打开SD-WebUI所在的目录，并确保其中包含Git组件。如果您没有安装Git组件，请从Git官网（<a href="https://git-scm.com/downloads%EF%BC%89%E4%B8%8B%E8%BD%BD%E5%B9%B6%E5%AE%89%E8%A3%85%E5%AE%83%E3%80%82%E5%A6%82%E6%9E%9C%E6%82%A8%E5%B7%B2%E7%BB%8F%E5%AE%89%E8%A3%85%E4%BA%86Git%E7%BB%84%E4%BB%B6%EF%BC%8C%E5%88%99%E5%8F%AF%E4%BB%A5%E5%B0%9D%E8%AF%95%E5%B0%86%E5%85%B6%E6%B7%BB%E5%8A%A0%E5%88%B0%E7%B3%BB%E7%BB%9F%E8%B7%AF%E5%BE%84%E4%B8%AD%E3%80%82%E5%9C%A8Windows%E7%B3%BB%E7%BB%9F%E4%B8%AD%EF%BC%8C%E6%82%A8%E5%8F%AF%E4%BB%A5%E6%8C%89%E7%85%A7%E4%BB%A5%E4%B8%8B%E6%AD%A5%E9%AA%A4%E8%BF%9B%E8%A1%8C%E6%93%8D%E4%BD%9C%EF%BC%9A%E5%8F%B3%E9%94%AE%E5%8D%95%E5%87%BB%E2%80%9C%E6%88%91%E7%9A%84%E7%94%B5%E8%84%91%E2%80%9D%E6%88%96%E2%80%9C%E6%9C%AC%E6%9C%BA%E2%80%9D%EF%BC%8C%E7%84%B6%E5%90%8E%E9%80%89%E6%8B%A9%E2%80%9C%E5%B1%9E%E6%80%A7%E2%80%9D%E3%80%82%E5%9C%A8%E5%B7%A6%E4%BE%A7%E7%9A%84%E9%9D%A2%E6%9D%BF%E4%B8%AD%EF%BC%8C%E5%8D%95%E5%87%BB%E2%80%9C%E9%AB%98%E7%BA%A7%E7%B3%BB%E7%BB%9F%E8%AE%BE%E7%BD%AE%E2%80%9D%E3%80%82%E5%9C%A8%E2%80%9C%E7%B3%BB%E7%BB%9F%E5%B1%9E%E6%80%A7%E2%80%9D%E5%AF%B9%E8%AF%9D%E6%A1%86%E4%B8%AD%EF%BC%8C%E5%8D%95%E5%87%BB%E2%80%9C%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E2%80%9D%E6%8C%89%E9%92%AE%E3%80%82%E5%9C%A8%E2%80%9C%E7%B3%BB%E7%BB%9F%E5%8F%98%E9%87%8F%E2%80%9D%E4%B8%AD%EF%BC%8C%E6%89%BE%E5%88%B0%E2%80%9CPath%E2%80%9D%E5%8F%98%E9%87%8F%EF%BC%8C%E5%B9%B6%E5%8D%95%E5%87%BB%E2%80%9C%E7%BC%96%E8%BE%91%E2%80%9D%E6%8C%89%E9%92%AE%E3%80%82%E5%9C%A8%E2%80%9C%E7%BC%96%E8%BE%91%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E2%80%9D%E5%AF%B9%E8%AF%9D%E6%A1%86%E4%B8%AD%EF%BC%8C%E5%8D%95%E5%87%BB%E2%80%9C%E6%96%B0%E5%BB%BA%E2%80%9D%E6%8C%89%E9%92%AE%EF%BC%8C%E5%B9%B6%E6%B7%BB%E5%8A%A0Git%E7%BB%84%E4%BB%B6%E6%89%80%E5%9C%A8%E7%9A%84%E8%B7%AF%E5%BE%84%E3%80%82%E5%8D%95%E5%87%BB%E2%80%9C%E7%A1%AE%E5%AE%9A%E2%80%9D%E6%8C%89%E9%92%AE%EF%BC%8C%E5%85%B3%E9%97%AD%E6%89%80%E6%9C%89%E5%AF%B9%E8%AF%9D%E6%A1%86%E3%80%82%E9%87%8D%E6%96%B0%E5%90%AF%E5%8A%A8SD-WebUI%EF%BC%8C%E7%9C%8B%E7%9C%8B%E6%98%AF%E5%90%A6%E4%BB%8D%E7%84%B6%E5%87%BA%E7%8E%B0%E7%9B%B8%E5%90%8C%E7%9A%84%E9%94%99%E8%AF%AF%E6%8F%90%E7%A4%BA%E3%80%82%E5%A6%82%E6%9E%9C%E6%82%A8%E8%BF%98%E6%98%AF%E6%97%A0%E6%B3%95%E8%A7%A3%E5%86%B3%E9%97%AE%E9%A2%98%EF%BC%8C%E8%AF%B7%E8%80%83%E8%99%91%E9%87%8D%E6%96%B0%E5%AE%89%E8%A3%85SD-WebUI%EF%BC%8C%E5%B9%B6%E7%A1%AE%E4%BF%9D%E6%82%A8%E5%B7%B2%E7%BB%8F%E6%AD%A3%E7%A1%AE%E5%AE%89%E8%A3%85%E4%BA%86Git%E7%BB%84%E4%BB%B6%E3%80%82">https://git-scm.com/downloads）下载并安装它。如果您已经安装了Git组件，则可以尝试将其添加到系统路径中。在Windows系统中，您可以按照以下步骤进行操作：右键单击“我的电脑”或“本机”，然后选择“属性”。在左侧的面板中，单击“高级系统设置”。在“系统属性”对话框中，单击“环境变量”按钮。在“系统变量”中，找到“Path”变量，并单击“编辑”按钮。在“编辑环境变量”对话框中，单击“新建”按钮，并添加Git组件所在的路径。单击“确定”按钮，关闭所有对话框。重新启动SD-WebUI，看看是否仍然出现相同的错误提示。如果您还是无法解决问题，请考虑重新安装SD-WebUI，并确保您已经正确安装了Git组件。</a></p><h2 id="sd-webui-报错mat1-and-mat2-shapes-cannot-be-multiplied的处理"><a href="#sd-webui-报错mat1-and-mat2-shapes-cannot-be-multiplied的处理" class="headerlink" title="(sd webui)报错mat1 and mat2 shapes cannot be multiplied的处理"></a>(sd webui)报错mat1 and mat2 shapes cannot be multiplied的处理</h2><p>在用webui转换游戏图标的风格时，使用controlnet固定图标样式，运行报错：RuntimeError: mat1 and mat2 shapes cannot be multiplied (154x1024 and 768x320)，报错说的是pytorch在进行矩阵乘法运算时，第一个矩阵的行数与第二矩阵的列数不相等，无法作乘法。</p><p>解决方法<br>一头雾水，查了github，google,百度都未找到解决方法，为了后续人少踩坑，把写问题记一下。当更换当前大模型后，再用同样的参数画图，然后就没报错了。<br>所以，解决方法是：更换大模型！<br>声明：不一定对，仅供参考，不喜勿喷。</p><h2 id="127-0-0-1-7860拒绝访问"><a href="#127-0-0-1-7860拒绝访问" class="headerlink" title="127.0.0.1:7860拒绝访问"></a>127.0.0.1:7860拒绝访问</h2><p>变数太多，提供几个可能解决方案：</p><ol><li>请确认开启网址终端是否还开着，并有显示Running on Local URL : <a href="http://127.0.0.1:7860的字样">http://127.0.0.1:7860的字样</a></li><li>网址改用<a href="http://localhost:7860访问">http://localhost:7860访问</a></li><li>用记事本开启C:\Windows\System32\drivers\etc\hosts，确认里面有无127.0.0.1 localhost这一行。</li><li>请确认电脑没有执行其他程序，导致端口占用或存在冲突。</li><li>开启CMD终端，执行ipconfig &#x2F;flushdns指令刷新DNS纪录</li><li>暂时关闭防火墙</li></ol><h2 id="RuntimeError-unexpected-EOF-expected-more-bytes-The-file-might-be-corrupted"><a href="#RuntimeError-unexpected-EOF-expected-more-bytes-The-file-might-be-corrupted" class="headerlink" title="RuntimeError: unexpected EOF, expected more bytes. The file might be corrupted."></a>RuntimeError: unexpected EOF, expected more bytes. The file might be corrupted.</h2><p>可能是文件毁损，删除这些文件夹：stable-diffusion-webui\models\GFPGAN、stable-diffusion-webui\models\Codeformer、stable-diffusion-webui\repositories\CodeForme</p><p>然后重启SD WebUI让它重新下载脸部模型。</p><h2 id="modules-devices-NansException-A-tensor-with-all-NaNs-was-produced-in-Unet"><a href="#modules-devices-NansException-A-tensor-with-all-NaNs-was-produced-in-Unet" class="headerlink" title="modules.devices.NansException: A tensor with all NaNs was produced in Unet."></a>modules.devices.NansException: A tensor with all NaNs was produced in Unet.</h2><p>此错误可能会发生在含有VAE的模型算图的时候，会导致算出来结果是黑图。</p><p>开启webui-user.bat，COMMANDLINE_ARGS后面额外加上–no-half –no-haf-vae引数。</p><h2 id="AssertionError-extension-access-disabled-because-of-commandline-flags"><a href="#AssertionError-extension-access-disabled-because-of-commandline-flags" class="headerlink" title="AssertionError: extension access disabled because of commandline flags"></a>AssertionError: extension access disabled because of commandline flags</h2><p>webui-user.bat(或webui-user.sh)的COMMANDLINE_ARGS有加入–share或–listen引数就会无法从网页安装扩展功能，这是出于安全性考虑。</p><p>你可以：</p><ol><li>将该引数删除。</li><li>额外加上–enable-insecure-extension-access引数试试。</li><li>改用Git clone的方式来安装扩展功能：关闭SD WebUI。于stable-diffusion-webui\extensions资料夹开启终端，输入git clone &lt;仓库地址&gt;下载扩展功能。</li></ol><h2 id="fatal-unable-to-access-Recv-failure-Connection-was-reset"><a href="#fatal-unable-to-access-Recv-failure-Connection-was-reset" class="headerlink" title="fatal: unable to access Recv failure: Connection was reset"></a>fatal: unable to access Recv failure: Connection was reset</h2><p>网路问题，访问Github的延迟，导致相关文件下载失败。</p><h2 id="No-module-named-pip"><a href="#No-module-named-pip" class="headerlink" title="No module named pip"></a><strong>No module named pip</strong></h2><p>于stable-diffusion-webui文件夹，右键＋SHIFT，开启终端，执行python3 -m ensurepip安装pip</p><p>然后删除venv文件夹，重新执行webui-user.bat</p><h2 id="RuntimeError-CUDA-Out-of-memory"><a href="#RuntimeError-CUDA-Out-of-memory" class="headerlink" title="RuntimeError: CUDA Out of memory"></a>RuntimeError: CUDA Out of memory</h2><p>显卡的VRAM不足。Stable Diffusion WebUI的显示卡VRAM最低要求为4GB，要无压力的玩建议8GB以上。</p><p>开启webui-user.bat，在COMMANDLINE_ARGS后面加入–mdevram或–lowvram引数，降低VRAM使用量。如果还是在算图时出现此讯息，建议降低算图的解析度，或是买张更好的显示卡，或是改用Google Colab。</p><h2 id="扩展功能导致的错误"><a href="#扩展功能导致的错误" class="headerlink" title="扩展功能导致的错误"></a>扩展功能导致的错误</h2><p>有时除了Stable Diffusion WebUI本身问题外，也有可能是你安装的扩充功能导致出错。</p><p>要Debug请尝试删除stable-diffusion-webui\extensions下的某个新安装的扩展功能文件夹，再尝试启动SD WebUI。</p><h2 id="提示-检测到SD-WebUI-进程退出状态不正常，建议前往疑难解答页面扫描错误记录或寻求其他帮助。"><a href="#提示-检测到SD-WebUI-进程退出状态不正常，建议前往疑难解答页面扫描错误记录或寻求其他帮助。" class="headerlink" title="提示:检测到SD-WebUI 进程退出状态不正常，建议前往疑难解答页面扫描错误记录或寻求其他帮助。"></a>提示:检测到SD-WebUI 进程退出状态不正常，建议前往疑难解答页面扫描错误记录或寻求其他帮助。</h2><p>方法 1、</p><p>git出问题了，不要管了，用这个方法重装<br>我原先软件本体代码就是下的zip解压的，会出现问题。GIT的hash散列值会是none，<br>你们应该装了GIT吧，建个新文件夹，在新建文件夹界面点地址栏输入cmd，打开cmd后输入<br>git clone <a href="http://jump2.bdimg.com/safecheck/index?url=rN3wPs8te/r8jfr8YhogjfUWFoMgIRa8DFG/XFAIQTAB/czLV3s78yUaNGxmyGJ34ySHx5raF9/GR4ncXUE2RSQJxFQ8FKqzy1KfUEdkPsP81hnVHhB8OZq5GKXvE2RIQz6PXpFQamF+4pkc674n/SPfBnJmIvV7CuPHU/2lzfuvRUaqI1zgng3QlbumM9NVMDxm7iZ2BjQ=">http://github.com/AUTOMATIC1111/stable-diffusion-webui.git</a><br>直接下一份新的本体程序，其它操作照常。还是不行的话别问我了，我也不知。</p><p>方法2、</p><p>去检查一下你们windows的cmd.exe文件是不是还在system32下面，如果还在执行一下 B启动报错、卡加载修复v3.bat 然后就能好了。如果被移动到SysWOW64下，那就复制一个回原来的地方，其它一样。</p><h2 id="sdwebui换去其他盘就启动不了"><a href="#sdwebui换去其他盘就启动不了" class="headerlink" title="sdwebui换去其他盘就启动不了"></a>sdwebui换去其他盘就启动不了</h2><p>解决方法。<br>1、打开SDWebUI的安装目录，找到config文件夹，打开config文件夹，找到config.json文件。<br>2、用文本编辑器打开config.json文件，找到其中的root字段，将其值修改为当前使用的盘符路径。<br>3、保存修改后的config.json文件，并重新启动SDWebUI。</p><h2 id="SD-WebUI（黑图）怎么解决？"><a href="#SD-WebUI（黑图）怎么解决？" class="headerlink" title="SD-WebUI（黑图）怎么解决？"></a>SD-WebUI（黑图）怎么解决？</h2><p>SD-WebUl（黑图）通常是由于浏览器缓存或者网络问题导致的。你可以尝试以下方法来解决这个问题：1. 清除浏览器缓存：在浏览器中按下Ctrl + Shift + Delete键，打开清除浏览器数据的选项，选择清除缓存，然后重新加载网页。2. 检查网络连接：确保你的网络连接正常，可以尝试重新连接网络或者重启路由器。3. 更换浏览器：如果以上方法都无法解决问题，可以尝试更换浏览器，或者升级浏览器版本。4. 检查网站是否正常：如果以上方法都无法解决问题，可能是网站本身出现了问题，你可以尝试等待一段时间，或者联系网站管理员寻求帮助。</p>]]></content>
      
      
      <categories>
          
          <category> 免费资源 </category>
          
          <category> 基础教程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AI智能 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>狐妖小红娘经典语录</title>
      <link href="/posts/27d8.html"/>
      <url>/posts/27d8.html</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="狐妖小红娘经典语录"><a href="#狐妖小红娘经典语录" class="headerlink" title="狐妖小红娘经典语录"></a>狐妖小红娘经典语录</h1><p>问世间情为何物，直教鹊桥难渡相思苦，直教化蝶难采同心甜，其实爱，不期待，就不会被伤害</p><p>傲来雾，花果香，定海一棒万妖朝。东海外，水帘中，齐天比高仙折腰。</p><p>只要你能幸福，我是谁，又有什么关系?记不记得住，又有什么关系啊!</p><p>问世间情为何物，直教银汉暗渡相思苦，直教缠绵破茧化蝶飞，直教逆神背天还家去，直教万转千修等一回。</p><p>万物有界，爱恨无由</p><p>如果我们能活着出去的话，千山万水，你能陪我一起看吗?</p><p>狐妖之力，源于至情，既是因情而生的力，又怎么会不让自己，为情所伤呢？这便是红线的宿命，红线仙的宿命…</p><p>前世你唤我妖仙姐姐， 今生我唤你道士哥哥。 前生我唤你道士， 今世你唤我小蠢货。</p><p>以吾之妖力,加汝之灵魂,启动转世续缘。</p><p>宁愿受千万剑所伤，不远委屈怀中人。万箭穿心终不悔，相视一笑轻王权。</p><p>玉璧传，金铃现，血染涂山为君颜</p><p>王权富贵 道门兵人无喜哀， 一剑轻挥除妖魔。 忽有一朝心生怜， 从此剑刃不染红。</p><p>江山默许山河醉， 相思树下几人归？</p><p>那年我守住了城，却没守住我的爱人</p><p>我以为 你来了 我以为 不会走 我以为 韶华在 我以为 你还留 我以为 可以挽君之手到白头 可是 我忘了这只是我以为</p><p>若此情付与东流兮，不予逃避 披星戴月未曾唏嘘，此情不渝</p><p>妖怪杀你，会光名正大告诉你，而人却会笑眯眯的杀掉你全家。</p><p>胆小如鼠也要表白清楚 单刀笑傲也要为我认输</p><p>聚散离合，乃是缘分，苦情巨树续的是缘，而有缘，未必有分</p><p>初相见，唇上血，千古第一为红颜。破阳炎，地寒天，泪中再见忆中颜。</p><p>我守住了一座城，却没守住一个人</p><p>容 聪明过人小狐狸， 珠玉算盘手中持。 纤纤玉指轻拨弄， 算尽天下人和事。</p><p>如果可以，愿来生你不要忘记我，我也不要忘记你那熟悉的温柔。</p><p>如果我们能活着出去，万水千山我都织给你看</p><p>万剑穿心终不悔，相视一笑轻王权。</p><p>因为喜欢你，我变成了你喜欢人的模样，可是我却忘了，我不再是我。</p><p>前世，我叫你妖仙姐姐，今生，你叫我道士哥哥；前世，你叫我二货道士，今生，我叫你小蠢货。我爱你，可以为了你对抗整个人类世界；我爱你，可以付出全身所有的妖力和记忆。伟大的相思树啊，让我们，来生再见。</p><p>相思树上有轮月，苦情树下有红衫。</p><p>月红难解相思苦，为君一语倾华年。</p>]]></content>
      
      
      <categories>
          
          <category> 经典语录 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 经典语录 </tag>
            
            <tag> 狐妖小红娘 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>webui部署常见问题汇总</title>
      <link href="/posts/479a.html"/>
      <url>/posts/479a.html</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="webui部署常见问题汇总"><a href="#webui部署常见问题汇总" class="headerlink" title="webui部署常见问题汇总"></a>webui部署常见问题汇总</h1><h2 id="问1：执行结果是一直到读取模型打开web页面都正常，然后点画图的时候进度不动，提示Missing-system-database-file-gfx1030-14-kdb-Performance-may-degrade"><a href="#问1：执行结果是一直到读取模型打开web页面都正常，然后点画图的时候进度不动，提示Missing-system-database-file-gfx1030-14-kdb-Performance-may-degrade" class="headerlink" title="问1：执行结果是一直到读取模型打开web页面都正常，然后点画图的时候进度不动，提示Missing system database file: gfx1030_14.kdb Performance may degrade."></a>问1：执行结果是一直到读取模型打开web页面都正常，然后点画图的时候进度不动，提示Missing system database file: gfx1030_14.kdb Performance may degrade.</h2><p>第一次跑图会自动编译miopen，稍等一下一个就会开始跑图了。</p><h2 id="问2：成功在lxc下安装，就是在终端执行代码后关了终端，网页端还在继续，linux小白，请问如何返回终端查看进程，退出程序该如何退出"><a href="#问2：成功在lxc下安装，就是在终端执行代码后关了终端，网页端还在继续，linux小白，请问如何返回终端查看进程，退出程序该如何退出" class="headerlink" title="问2：成功在lxc下安装，就是在终端执行代码后关了终端，网页端还在继续，linux小白，请问如何返回终端查看进程，退出程序该如何退出"></a>问2：成功在lxc下安装，就是在终端执行代码后关了终端，网页端还在继续，linux小白，请问如何返回终端查看进程，退出程序该如何退出</h2><p>lxc应该是一种容器吧，关闭终端不能容器还在运行的，停掉容器应该就停了。可以每次关闭终端前按Ctrl+c就可以关闭程序了。</p><h2 id="问3：请问一下虚拟化环境下装显卡驱动是识别不到显卡吗，我这边一直提示gpu-not-found。"><a href="#问3：请问一下虚拟化环境下装显卡驱动是识别不到显卡吗，我这边一直提示gpu-not-found。" class="headerlink" title="问3：请问一下虚拟化环境下装显卡驱动是识别不到显卡吗，我这边一直提示gpu not found。"></a>问3：请问一下虚拟化环境下装显卡驱动是识别不到显卡吗，我这边一直提示gpu not found。</h2><p>虚拟化除非可以直通显卡，比如esxi或pve可以，其他的不行。VM workstation宿主型虚拟化，为了流畅会把显卡虚拟化成SVGA显卡，是不能跑图的。</p><h2 id="问4：请问出现Running-on-local-URL-http-127-0-0-1-6006-To-create-a-public-link-set-‘share-x3D-true’-in-‘launch’之后应该怎么操作？需要手动打开浏览器吗？浏览器在哪里呢？"><a href="#问4：请问出现Running-on-local-URL-http-127-0-0-1-6006-To-create-a-public-link-set-‘share-x3D-true’-in-‘launch’之后应该怎么操作？需要手动打开浏览器吗？浏览器在哪里呢？" class="headerlink" title="问4：请问出现Running on local URL:http://127.0.0.1:6006  To create a public link,set ‘share&#x3D;true’ in ‘launch’之后应该怎么操作？需要手动打开浏览器吗？浏览器在哪里呢？"></a>问4：请问出现Running on local URL:<a href="http://127.0.0.1:6006/">http://127.0.0.1:6006</a>  To create a public link,set ‘share&#x3D;true’ in ‘launch’之后应该怎么操作？需要手动打开浏览器吗？浏览器在哪里呢？</h2><p>如果Linux有图形界面就打开浏览器就可以，如果需要其他设备链接需要在start.sh args里加–listen</p><h2 id="问5：xformers是不是不支持A卡？"><a href="#问5：xformers是不是不支持A卡？" class="headerlink" title="问5：xformers是不是不支持A卡？"></a>问5：xformers是不是不支持A卡？</h2><p>是的，这是n卡才可以使用的。</p><h2 id="问6：对linux环境有要求吗，我都被python3-8和3-10搞得人都傻了，到底要用哪个？"><a href="#问6：对linux环境有要求吗，我都被python3-8和3-10搞得人都傻了，到底要用哪个？" class="headerlink" title="问6：对linux环境有要求吗，我都被python3.8和3.10搞得人都傻了，到底要用哪个？"></a>问6：对linux环境有要求吗，我都被python3.8和3.10搞得人都傻了，到底要用哪个？</h2><p>部署包没有要求，但显卡驱动有要求，一般要与驱动相匹配的Ubuntu系统，amd的部署包是python3.8的，3.8与amd显卡好像兼容性更高一些，如果是n卡直接3.10就行</p><h2 id="问7：我看教程里都是连带着装了torch-rocm-还有miopen，这些也是amdgpu驱动的一部分吗？"><a href="#问7：我看教程里都是连带着装了torch-rocm-还有miopen，这些也是amdgpu驱动的一部分吗？" class="headerlink" title="问7：我看教程里都是连带着装了torch rocm 还有miopen，这些也是amdgpu驱动的一部分吗？"></a>问7：我看教程里都是连带着装了torch rocm 还有miopen，这些也是amdgpu驱动的一部分吗？</h2><p>torch不是其他的是，部署包自带一个rocm5.1.1+1.13的torch,如果运行webui不报cuda错，那就代表torch和显卡链接正常。</p><h2 id="问8：自带rocm和torch的话，我在装显卡驱动这一步就装了是不是会有影响？"><a href="#问8：自带rocm和torch的话，我在装显卡驱动这一步就装了是不是会有影响？" class="headerlink" title="问8：自带rocm和torch的话，我在装显卡驱动这一步就装了是不是会有影响？"></a>问8：自带rocm和torch的话，我在装显卡驱动这一步就装了是不是会有影响？</h2><p>不会的，部署包的环境在conda虚拟环境中，不会对系统的产生影响。</p><h2 id="问9：AssertionError-Torch-is-not-able-to-use-GPU-add-–skip-torch-cuda-test-to-COMMANDLINE-ARGS-variable-to-disable-this-check，不知道怎么处理了-з」∠"><a href="#问9：AssertionError-Torch-is-not-able-to-use-GPU-add-–skip-torch-cuda-test-to-COMMANDLINE-ARGS-variable-to-disable-this-check，不知道怎么处理了-з」∠" class="headerlink" title="问9：AssertionError: Torch is not able to use GPU; add –skip-torch-cuda-test to COMMANDLINE_ARGS variable to disable this check，不知道怎么处理了_(:з」∠)_"></a>问9：AssertionError: Torch is not able to use GPU; add –skip-torch-cuda-test to COMMANDLINE_ARGS variable to disable this check，不知道怎么处理了_(:з」∠)_</h2><p>这是没有支持的显卡或是显卡torch和显卡驱动不匹配导致的。</p><h2 id="问10：是不是也是在webui文件夹下进入终端并且进入（sdwebui）虚拟环境后再输入该指令，还是进入终端后（base）就直接执行指令？"><a href="#问10：是不是也是在webui文件夹下进入终端并且进入（sdwebui）虚拟环境后再输入该指令，还是进入终端后（base）就直接执行指令？" class="headerlink" title="问10：是不是也是在webui文件夹下进入终端并且进入（sdwebui）虚拟环境后再输入该指令，还是进入终端后（base）就直接执行指令？"></a>问10：是不是也是在webui文件夹下进入终端并且进入（sdwebui）虚拟环境后再输入该指令，还是进入终端后（base）就直接执行指令？</h2><p>需要切到（sd-webui）环境下运行。</p><h2 id="问11：什么配置可以运行webui？"><a href="#问11：什么配置可以运行webui？" class="headerlink" title="问11：什么配置可以运行webui？"></a>问11：什么配置可以运行webui？</h2><p>CPU：2核以上；内存：32GB（包括SWAP交换空间，以7GB模型运行为标准）至少需要8GB（不包括SWAP交换）；一张支持cuda或rocm的显卡，显存8GB及以上（可以训练），最低4GB（只能小分辨率跑图）。</p><h2 id="问12：这个用a卡能调用全部显存吗？"><a href="#问12：这个用a卡能调用全部显存吗？" class="headerlink" title="问12：这个用a卡能调用全部显存吗？"></a>问12：这个用a卡能调用全部显存吗？</h2><p>由于pytorch本身要占用一些显存，使用这个其实都可以全部调用。</p><h2 id="问13：这个部署是可以自动更新的吗-和其他大佬做的整合包有什么不同？"><a href="#问13：这个部署是可以自动更新的吗-和其他大佬做的整合包有什么不同？" class="headerlink" title="问13：这个部署是可以自动更新的吗?和其他大佬做的整合包有什么不同？"></a>问13：这个部署是可以自动更新的吗?和其他大佬做的整合包有什么不同？</h2><p>启动时是不会更新的，可以使用脚本或手动gitpull更新，没有进行魔改，其实和其他没什么区别。</p><h2 id="问14：这个是要自己安装插件吗-能否出个详细教程。"><a href="#问14：这个是要自己安装插件吗-能否出个详细教程。" class="headerlink" title="问14：这个是要自己安装插件吗?能否出个详细教程。"></a>问14：这个是要自己安装插件吗?能否出个详细教程。</h2><p>插件已经自带了一些，一般是不用自己再装了，如果需要的插件没有，可以按照下面方法下载使用：</p><p>浏览器打开这个链接：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://raw.githubusercontent.com/wiki/AUTOMATIC1111/stable-diffusion-webui/Extensions-index.md</span><br></pre></td></tr></table></figure><p>按Ctrl+F在浏览器中搜索插件的名字，复制url的那个地址，然后在webui的extensions文件夹下，执行：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/Mikubill/sd-webui-controlnet.git</span><br></pre></td></tr></table></figure><p>重启webui</p><h2 id="问15：请问linux必须是配备了显卡的gpu计算型实例么？"><a href="#问15：请问linux必须是配备了显卡的gpu计算型实例么？" class="headerlink" title="问15：请问linux必须是配备了显卡的gpu计算型实例么？"></a>问15：请问linux必须是配备了显卡的gpu计算型实例么？</h2><p>是的  需要有GPU  镜像也要选带GPU的。一般会自带驱动。</p><h2 id="问16：我想知道如何接上公网，然后可以在手机里生成呢，这个up知道吗？"><a href="#问16：我想知道如何接上公网，然后可以在手机里生成呢，这个up知道吗？" class="headerlink" title="问16：我想知道如何接上公网，然后可以在手机里生成呢，这个up知道吗？"></a>问16：我想知道如何接上公网，然后可以在手机里生成呢，这个up知道吗？</h2><p>有公网ip的话 start.sh args里加个–listen 就行，没有 就加–share ，–gradio-auth 用户名:密码 是设置webui的用户名和密码。</p><h2 id="问17：我用你的整合包，然后我自己之前装的都是分辨率一调大就自动关机6750xt的显卡只能跑512-768以下的不然就自动关机，有啥办法吗？12g的显存"><a href="#问17：我用你的整合包，然后我自己之前装的都是分辨率一调大就自动关机6750xt的显卡只能跑512-768以下的不然就自动关机，有啥办法吗？12g的显存" class="headerlink" title="问17：我用你的整合包，然后我自己之前装的都是分辨率一调大就自动关机6750xt的显卡只能跑512*768以下的不然就自动关机，有啥办法吗？12g的显存"></a>问17：我用你的整合包，然后我自己之前装的都是分辨率一调大就自动关机6750xt的显卡只能跑512*768以下的不然就自动关机，有啥办法吗？12g的显存</h2><p>有的a卡就是这样跑不了太大的图的，而且可能驱动有bug，会超功率跑关机，目前是没有办法的。</p><h2 id="问18：请问一下您的stable-diffusion部署教程中，pip-install-r-stable-diffusion-webui-x2F-requirements-versions-txt-这个安装依赖命令输入后提示找不到此路径，是什么问题啊？"><a href="#问18：请问一下您的stable-diffusion部署教程中，pip-install-r-stable-diffusion-webui-x2F-requirements-versions-txt-这个安装依赖命令输入后提示找不到此路径，是什么问题啊？" class="headerlink" title="问18：请问一下您的stable diffusion部署教程中，pip install -r stable-diffusion-webui&#x2F;requirements_versions.txt 这个安装依赖命令输入后提示找不到此路径，是什么问题啊？"></a>问18：请问一下您的stable diffusion部署教程中，pip install -r stable-diffusion-webui&#x2F;requirements_versions.txt 这个安装依赖命令输入后提示找不到此路径，是什么问题啊？</h2><p>一般是没有在webui文件夹下，终端先cd到stable-diffusion-webui下，再运行上面这条命令就行了。</p><h2 id="问19：这个webui安装完，相当于只是做了一个前端页面？还得导入模型后，才能正常使用文字生成图片吗"><a href="#问19：这个webui安装完，相当于只是做了一个前端页面？还得导入模型后，才能正常使用文字生成图片吗" class="headerlink" title="问19：这个webui安装完，相当于只是做了一个前端页面？还得导入模型后，才能正常使用文字生成图片吗?"></a>问19：这个webui安装完，相当于只是做了一个前端页面？还得导入模型后，才能正常使用文字生成图片吗?</h2><p>是的，需要导入模型，命令：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mv &#123;你的模型文件名.ckpt&#125; stable-diffusion-webui/models/Stable-diffusion/</span><br><span class="line">mv &#123;你的模型文件名.safetensors&#125; stable-diffusion-webui/models/Stable-diffusion/</span><br><span class="line">mv &#123;你的vae文件名.vae.ckpt&#125; stable-diffusion-webui/models/VAE/</span><br><span class="line">mv &#123;你的lora模型文件名.ckpt&#125; stable-diffusion-webui/models/lora/</span><br><span class="line">mv &#123;你的lora模型文件名.safetensors&#125; stable-diffusion-webui/models/lora/</span><br></pre></td></tr></table></figure><h2 id="问20：还有个问题，我的显卡是6900xt，然后这边显示gfx1030，正常吗？"><a href="#问20：还有个问题，我的显卡是6900xt，然后这边显示gfx1030，正常吗？" class="headerlink" title="问20：还有个问题，我的显卡是6900xt，然后这边显示gfx1030，正常吗？"></a>问20：还有个问题，我的显卡是6900xt，然后这边显示gfx1030，正常吗？</h2><p>6900xt要模拟成gfx1030运行，这是正常的。</p><h2 id="问21：问下这些大部分是用novalAI的模型自己训练出来的么，比如civitai这个，好像novalai也有一个7g左右的完整模型。"><a href="#问21：问下这些大部分是用novalAI的模型自己训练出来的么，比如civitai这个，好像novalai也有一个7g左右的完整模型。" class="headerlink" title="问21：问下这些大部分是用novalAI的模型自己训练出来的么，比如civitai这个，好像novalai也有一个7g左右的完整模型。"></a>问21：问下这些大部分是用novalAI的模型自己训练出来的么，比如civitai这个，好像novalai也有一个7g左右的完整模型。</h2><p>是的 一般二次元一般都是novel的底膜，三次元一般sd1.5 或其他版本的。</p><h2 id="问22：服务器上有8张卡，可以选具体哪些卡跑吗？"><a href="#问22：服务器上有8张卡，可以选具体哪些卡跑吗？" class="headerlink" title="问22：服务器上有8张卡，可以选具体哪些卡跑吗？"></a>问22：服务器上有8张卡，可以选具体哪些卡跑吗？</h2><p>可以，指定其中某张显卡来跑图，在start.sh加”–device-id {显卡id}”参数，显卡id是需要跑图的显卡编号，webui跑图现在只能一张显卡跑.</p><h2 id="问23：我在扩展那一栏加载时，它显示建立安全链接失败，如何解决呀"><a href="#问23：我在扩展那一栏加载时，它显示建立安全链接失败，如何解决呀" class="headerlink" title="问23：我在扩展那一栏加载时，它显示建立安全链接失败，如何解决呀?"></a>问23：我在扩展那一栏加载时，它显示建立安全链接失败，如何解决呀?</h2><p>浏览器打开这个链接：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://raw.githubusercontent.com/wiki/AUTOMATIC1111/stable-diffusion-webui/Extensions-index.md</span><br></pre></td></tr></table></figure><h2 id="问24：我遇到一个问题，我想试试不同种类的底模，文件也放到对应路径models-Stable-diffusion，但是输入tag开始绘图后控制台经常提示找不到模型文件，然后自动调用另一个底模，想问问这种情况怎么解决？"><a href="#问24：我遇到一个问题，我想试试不同种类的底模，文件也放到对应路径models-Stable-diffusion，但是输入tag开始绘图后控制台经常提示找不到模型文件，然后自动调用另一个底模，想问问这种情况怎么解决？" class="headerlink" title="问24：我遇到一个问题，我想试试不同种类的底模，文件也放到对应路径models\Stable-diffusion，但是输入tag开始绘图后控制台经常提示找不到模型文件，然后自动调用另一个底模，想问问这种情况怎么解决？"></a>问24：我遇到一个问题，我想试试不同种类的底模，文件也放到对应路径models\Stable-diffusion，但是输入tag开始绘图后控制台经常提示找不到模型文件，然后自动调用另一个底模，想问问这种情况怎么解决？</h2><p>好像是因为直接复制tag导致的，会把作者使用的模型也复制过来，本地找不到tag中的模型就用其他已存在的替代了。</p><h2 id="问25：请问一下，我在autodl上安装一键包，如果重新安装conda环境，能正常安装，但是这个实例在这次关闭之后就会显示Jupiterlab发生错误，再也打不开了，不重新安装conda环境，解压cache包的时候就会显示找不到这个文件，之后无法conda-activate，请问该如何解决呢？"><a href="#问25：请问一下，我在autodl上安装一键包，如果重新安装conda环境，能正常安装，但是这个实例在这次关闭之后就会显示Jupiterlab发生错误，再也打不开了，不重新安装conda环境，解压cache包的时候就会显示找不到这个文件，之后无法conda-activate，请问该如何解决呢？" class="headerlink" title="问25：请问一下，我在autodl上安装一键包，如果重新安装conda环境，能正常安装，但是这个实例在这次关闭之后就会显示Jupiterlab发生错误，再也打不开了，不重新安装conda环境，解压cache包的时候就会显示找不到这个文件，之后无法conda activate，请问该如何解决呢？"></a>问25：请问一下，我在autodl上安装一键包，如果重新安装conda环境，能正常安装，但是这个实例在这次关闭之后就会显示Jupiterlab发生错误，再也打不开了，不重新安装conda环境，解压cache包的时候就会显示找不到这个文件，之后无法conda activate，请问该如何解决呢？</h2><p>使用一键包覆盖conda的话会导致autodl的Jupiterlab打不开，可以在运行部署包脚本时在“是否覆盖conda”选否，显示部署完成后先执行conda init命令再bash命令应该就正常了</p><h2 id="问26：好像版本不兼容咋办呢？"><a href="#问26：好像版本不兼容咋办呢？" class="headerlink" title="问26：好像版本不兼容咋办呢？"></a>问26：好像版本不兼容咋办呢？</h2><p>WARNING【XFORMERS】: xFormers can’t load C++&#x2F;CUDA extensions. xFormers was built for:PyTorch 1.13.1+rocm5.2 with CUDA None (you have 1.13.1+rocm5.2) Python  3.10.9 (you have 3.10.9) Please reinstall xformers (see<a href="https://github.com/facebookresearch/xformers#installing-xformers">https://github.com/facebookresearch/xformers#installing-xformers</a>)<br>A卡是不支持xformers的。</p><h2 id="问27：win系统，一键安装sd-webui-install-sh-输入了1-然后回车-窗口就闪退了…-请问是什么情况呀？"><a href="#问27：win系统，一键安装sd-webui-install-sh-输入了1-然后回车-窗口就闪退了…-请问是什么情况呀？" class="headerlink" title="问27：win系统，一键安装sd-webui install.sh 输入了1 然后回车 窗口就闪退了…. 请问是什么情况呀？"></a>问27：win系统，一键安装sd-webui install.sh 输入了1 然后回车 窗口就闪退了…. 请问是什么情况呀？</h2><p>部署包是针对linux的，win的话肯定会闪退啊</p><h2 id="问28：这个是自动安装miniconda然后建立了一个conda虚拟环境吗？整合包里有dreambooth吗？最近从github原仓库安装webui要疯了，装dreambooth插件好多依赖版本对不上。"><a href="#问28：这个是自动安装miniconda然后建立了一个conda虚拟环境吗？整合包里有dreambooth吗？最近从github原仓库安装webui要疯了，装dreambooth插件好多依赖版本对不上。" class="headerlink" title="问28：这个是自动安装miniconda然后建立了一个conda虚拟环境吗？整合包里有dreambooth吗？最近从github原仓库安装webui要疯了，装dreambooth插件好多依赖版本对不上。"></a>问28：这个是自动安装miniconda然后建立了一个conda虚拟环境吗？整合包里有dreambooth吗？最近从github原仓库安装webui要疯了，装dreambooth插件好多依赖版本对不上。</h2><p>是的，已经带了环境和dreambooth插件。</p><h2 id="问29：我刚装了你的包。但是我用dreambooth的时候页面上的学习率明明是0-000002，但在后台打印的学习率是0-002，你有这个现象吗，包括训练的进度条那里显示的学习率也是0-002"><a href="#问29：我刚装了你的包。但是我用dreambooth的时候页面上的学习率明明是0-000002，但在后台打印的学习率是0-002，你有这个现象吗，包括训练的进度条那里显示的学习率也是0-002" class="headerlink" title="问29：我刚装了你的包。但是我用dreambooth的时候页面上的学习率明明是0.000002，但在后台打印的学习率是0.002，你有这个现象吗，包括训练的进度条那里显示的学习率也是0.002"></a>问29：我刚装了你的包。但是我用dreambooth的时候页面上的学习率明明是0.000002，但在后台打印的学习率是0.002，你有这个现象吗，包括训练的进度条那里显示的学习率也是0.002</h2><p>这个可能是插件的bug，可以试试使用git pull更新一下插件。</p>]]></content>
      
      
      <categories>
          
          <category> 免费资源 </category>
          
          <category> 基础教程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AI智能 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SD WEBUI 基础教程（三）</title>
      <link href="/posts/b99f.html"/>
      <url>/posts/b99f.html</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="使用tags的小技巧及关键词"><a href="#使用tags的小技巧及关键词" class="headerlink" title="使用tags的小技巧及关键词"></a>使用tags的小技巧及关键词</h1><h2 id="一、tags小技巧"><a href="#一、tags小技巧" class="headerlink" title="一、tags小技巧"></a>一、tags小技巧</h2><p>分享一些tags<br>1、构图<br>在使用SD模型生成图片时，需要注意一些细节。SD模型的训练数据来自于网络，因此tags（标签）更倾向于使用口语化表达，而非专业术语。这意味着一些常见的景别描述如”medium shot”（中景）和”full shot”（全景）可能无法产生理想的效果，因为这些表述很少出现在训练数据中。然而，也有一些例外情况。有些模型在微调过程中可能添加了更专业的tags，这样就能够更好地生成对应的景别效果。<br>另外，还有一些特定的术语如”cowboy shot”（牛仔镜头）可能无法被一些模型正确识别，导致生成的图片中出现牛仔服装的人物。为了避免这种情况，可以通过在negative prompt（负向提示侧）中加入其他关键词，如”full body”（全身）或”closeup”（特写），以限制生成范围，从而得到所需的景别效果。<br>再次提醒，使用这些tags生成的图片不会100%地符合预期。因此，不能仅仅依靠单张图片的内容来判断prompt是否合适。为了达到更好的效果，建议一次性生成多张图片，然后根据需要情况来调整提示。<br>当我们观察生成的多张图片时，可以结合我们的需求和判断来调整prompt。根据生成的结果，我们可以选择调整关键词、添加限制条件或者尝试不同的表达方式。通过这种迭代的方法，我们可以逐渐接近想要的效果。<br>以下是一些示例：</p><p><img src="https://img.99shopla.com/jingbie.jpg" alt="jingbie.jpg"></p><p><img src="https://img.99shopla.com/jiaodu.jpg" alt="jiaodu.jpg"></p><p>2、风格<br>在使用标签生成图片时，有时会发现使用一些风格类的关键词，如”illustration”（插画）、”cartoon”（卡通）等，生成的图片风格非常多样。这是因为训练数据中的插画风格本身就包含了很多不同的风格变化。为了更好地控制生成的结果，我们可以进一步限定生成范围：</p><ol><li>通过添加关键词如”flat design”（扁平化设计）、”2D”等，来生成更平面的插画风格。这样可以使生成的图片更加符合平面插画的特点。另外，通过再negative prompt添加与期望风格相反的关键词，也能够限定生成的结果，以获得与之相反的风格效果。</li><li>通过添加相关艺术家的名字或艺术家关键词，可以引导模型生成更具特征性和独特的图片。艺术家关键词通常与特定的艺术风格或创作方式相关，因此可以帮助我们缩小生成范围，更加准确地获得所需的效果。<br>以下是一些示例：<br><img src="https://img.99shopla.com/fengge.jpg" alt="fengge.jpg"></li></ol><p>3、媒介<br>单独使用媒介tag，也会出现风格非常多样的图片，原因跟之前提到的完全一样，解决方法也完全相同，这里不再赘述。<br>以下是一些示例：</p><p><img src="https://img.99shopla.com/meijie.jpg" alt="meijie.jpg"></p><p>4、增加细节<br>生成的图片如果觉得细节不够丰富，那么就可以添加下面的关键词来改进<br>Highly detailed：通过观察人物的衣服和背后的蘑菇等细节，可以明显看出与对比图相比，添加了这个关键词后，生成的图片会更具细节。<br>Intricate pattern：通过添加更多的纹理，特别是在人物的衣服上，可以使生成的图片更加丰富多样。<br>Ornate：通过添加装饰品，例如人物头发上的发夹，以及额外的装饰物在手臂上，可以增添图片的华丽感。<br>Vary：Vary是一种渲染引擎，有时候能够产生出不错的效果。可以尝试使用这个关键词来获得更丰富的渲染效果。<br>以下是一些示例：</p><p><img src="https://img.99shopla.com/huamianxijie.jpg" alt="huamianxijie.jpg"></p><p>5、灯光效果<br>调整灯光效果是一项相对困难的任务，因为SD模型缺乏对三维空间的理解能力，因此很难准确呈现不同方位灯光的效果。然而，通过添加相关的关键词仍然可以产生一定效果。这是因为虽然SD无法理解三维空间，但它对于图片的色调和明暗有很好的学习能力。<br>例如，关键词”back light”虽然无法真正呈现背光效果，但会使人物正面变暗，并给头发产生发光的效果。另外，关键词”hard light”相对于”soft light”会产生更高对比度的图片，这是使用硬光的特点之一。如果你有摄影经验，这应该不难理解。<br>需要注意的是，有些光效关键词还可以用其他表达方式来表示。例如，”side light”也可以表达为”side lights”。如果发现效果不明显，可以尝试添加更多类似的词语来进一步调整灯光效果。其他类型的关键词也可能有相似的情况。</p><p><img src="https://img.99shopla.com/guangxiao.jpg" alt="guangxiao.jpg"></p><p>6、颜色氛围<br>这个不多解释，非常直观。<br>SD对颜色信息的学习没啥难度，因此操控起来显得比较轻松。<br>以下是一些示例：</p><p><img src="https://img.99shopla.com/yansefenwei.jpg" alt="yansefenwei.jpg"></p>]]></content>
      
      
      <categories>
          
          <category> 免费资源 </category>
          
          <category> 基础教程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AI智能 </tag>
            
            <tag> AI绘画 </tag>
            
            <tag> AI绘图 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SD WEBUI 基础教程（二）</title>
      <link href="/posts/b5e6.html"/>
      <url>/posts/b5e6.html</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="给新人的sd-webui安装教程"><a href="#给新人的sd-webui安装教程" class="headerlink" title="给新人的sd webui安装教程"></a>给新人的sd webui安装教程</h1><h2 id="prompt提示词结构"><a href="#prompt提示词结构" class="headerlink" title="prompt提示词结构"></a>prompt提示词结构</h2><p>一个好的prompt应该是详细而具体的。比如，如果你只输入”cat”（猫），生成的图片结果会非常广泛。但是如果你能够缩小范围，例如限定猫的品种、颜色甚至姿势，那么生成的图片就会更接近你的预期。通过提供更具体的描述，可以缩小模型的预测范围，从而更容易得到你想要的结果。<br>那么如何尽可能地缩小模型的预测范围？或者说，如何撰写一个详细而具体的提示？一个好的提示应该具备以下要素：</p><ol><li>主体：明确指出所期望生成图像的主要内容，例如动物、植物或其他物品。包括主体动作、表情、眼睛状态、服饰、装饰物等，以丰富主体的特征。</li><li>背景：描述主体所处的环境，包括室内或室外，光线条件等，以帮助模型更好地理解所期望的情境。</li><li>构图：包括景别、拍摄角度、景深等，以控制图像的组成和视角。</li><li>风格：指定所期望的图像风格，例如插画、卡通、水彩、3D、超现实、复古等，同时考虑画面明暗、对比度等视觉效果。</li><li>媒介：说明绘画使用的特定材料或媒介，例如油画、电子绘画、铅笔画等。</li><li>画面清晰度：使用能提高画面锐度的关键词，避免模糊的描述。</li><li>灯光效果：指定所期望的灯光效果，例如侧光、逆光、环境光等，以增强图像的氛围和视觉效果。</li><li>颜色氛围：输入合适的颜色关键词，可以改变整个画面的色调<br>通过综合运用这些要素，你可以撰写一个详细而具体的提示词，从而更精确地指导模型生成符合你期望的图像。刚开始接触绘画的新人先按照这个模板撰写提示词，融会贯通之后就可以自由改变提示词了。</li></ol><h2 id="举个例子"><a href="#举个例子" class="headerlink" title="举个例子"></a>举个例子</h2><h3 id="1、主体"><a href="#1、主体" class="headerlink" title="1、主体"></a>1、主体</h3><p>主体（Subject）即是你希望在图像中呈现的主要内容。然而，许多新人常犯的一个错误是未能对主体进行足够详尽的描述。<br>比如，如果你想要生成一个精灵的图片，许多初次接触AI绘画的新手可能会这样写：<br>Prompt: an elf (一个精灵)<br>这样的表述过于简洁，给模型圈定的生成范围还很庞大。这个精灵是在坐着还是站着？表情是怎样的？穿着怎样的衣服？这些都是我们需要详细描述清楚的，否则范围就会很广，生成的图片内容也会变化很大。<br>因此，为了更准确地指导模型生成预期的图像，我们就需要提供更具体的描述。例如：<br>模型：Realistic Vision V2.0<br>Prompt: a beautiful girl as an enchanting forest elf sitting on a tree, serene expression, wearing a flowing green dress with intricate details, (一个如迷人的森林精灵般的美丽女孩坐在一棵树上，表情安宁，穿着一件带有复杂细节的飘逸绿色连衣裙)</p><p><img src="https://img.99shopla.com/jingling1.jpg" alt="jingling1.jpg"></p><h3 id="2、背景"><a href="#2、背景" class="headerlink" title="2、背景"></a>2、背景</h3><p>主体描述已经完善，但是我们还需要提供主体所处的环境信息，以便更好地指导模型生成图像。通过输入环境关键词就可以进一步限制图像生成的范围。<br>因此，主体所属的环境也是需要进行描述的。将地点，时间，环境元素，天气，光线条件等等都可以输入进prompt来影响背景效果。<br>在这个例子中，精灵是在树林里的，当然也可以在其它地方，可以结合你自己的想象力去创造更新颖的画面。在这里我就将环境设定在树林里。<br>Prompt：a beautiful girl as an enchanting forest elf sitting on a tree, serene expression, wearing a flowing green dress with intricate details, forest dominated by towering trees, sunny, warm sunlight, (一个如迷人的森林精灵般的美丽女孩坐在一棵树上，表情安宁，穿着一件带有复杂细节的飘逸绿色连衣裙，参天大树构成的森林，晴天，温暖的阳光)</p><p><img src="https://img.99shopla.com/jingling2.jpg" alt="jingling2.jpg"></p><h3 id="3、构图"><a href="#3、构图" class="headerlink" title="3、构图"></a>3、构图</h3><p>构图包括景别、拍摄角度、景深等等。<br>景别即人物占画面比例的大小，比如full shot（全景）能够显示被拍摄对象的整个身体，包括头到脚的范围。full shot更通俗的表达式full body，即全身。需要注意的是，有些模型不能识别full shot，需要尝试使用full body才能产生效果。相似的，upper body或者half body则指的是上半身，即腰部以上。更多的关键词，下期我再专门总结一篇。<br>从上面生成的图片来看，很多都是上半身的图像，但我更想要全身的图像，那么我继续添加关键词：<br>Prompt：a beautiful girl as an enchanting forest elf sitting on a tree, serene expression, wearing a flowing green dress with intricate details, forest dominated by towering trees, sunny, warm sunlight, full body, (一个如迷人的森林精灵般的美丽女孩坐在一棵树上，表情安宁，穿着一件带有复杂细节的飘逸绿色连衣裙，参天大树构成的森林，晴天，温暖的阳光，全身像)</p><p><img src="https://img.99shopla.com/jingling3.jpg" alt="jingling3.jpg"></p><p>可以发现，当我添加full body之后，确实可以生成全身像，但是能发现一个明确缺点，即容易产生畸形人物，这在半身像中却是不常见的。生成全身像会导致任务畸形是许多模型共同的缺点，这可能是因为训练模型使用的材料缺乏这类图片的原因。</p><h3 id="4、风格"><a href="#4、风格" class="headerlink" title="4、风格"></a>4、风格</h3><p>设定风格能够对图片产生非常大的影响，不同的风格能够给人不同的感觉，可以使用的关键词有很多。例如fantasy（幻想虚拟风格）、hyperrealistic（超现实主义的）、Modernist（现代主义的）、illustration（插画）等等。这里分享一下小技巧，一个能够准确且有效的改变画面风格的方法是加入特定的画家的名字。比如我加入Alan Lee，他是一个插画家：<br>Prompt: a beautiful girl as an enchanting forest elf sitting on a tree, serene expression, wearing a flowing green dress with intricate details, forest dominated by towering trees, sunny, warm sunlight, full body, by Alan Lee, fantasy, hyperrealistic, (一个如迷人的森林精灵般的美丽女孩坐在一棵树上，表情安宁，穿着一件带有复杂细节的飘逸绿色连衣裙，参天大树构成的森林，晴天，温暖的阳光，全身像，Alan Lee画的，幻想、超现实的)</p><p><img src="https://img.99shopla.com/jingling4.jpg" alt="jingling4.jpg"></p><p>可以发现，风格的确发生了一些变化，已经出现了Alan Lee的绘画风格了。效果不是很明显，但是没关系，先用着。</p><h3 id="5、媒介"><a href="#5、媒介" class="headerlink" title="5、媒介"></a>5、媒介</h3><p>媒介即绘画使用的特定材料，例如油画、电子绘画、铅笔画、水彩、墨水等等。<br>不同媒介对画面的质感能够产生显著的影响，比如：油画能够使整个画面产生特殊的纹理；胶片则会给画面添加颗粒感；<br>我觉得这个水彩效果对这个主题来说更合适，所以我添加了watercolor（水彩）<br>Prompt：a beautiful girl as an enchanting forest elf sitting on a tree, serene expression, wearing a flowing green dress with intricate details, forest dominated by towering trees, sunny, warm sunlight, full body, by Alan Lee, fantasy, hyperrealistic, watercolor, (一个如迷人的森林精灵般的美丽女孩坐在一棵树上，表情安宁，穿着一件带有复杂细节的飘逸绿色连衣裙，参天大树构成的森林，晴天，温暖的阳光，全身像，Alan Lee画的，幻想的，超现实的，水彩)</p><p><img src="https://img.99shopla.com/jingling5.jpg" alt="jingling5.jpg"></p><p>可以发现，添加watercolor关键词已经使画面产生了水彩的效果。</p><h3 id="6、画面清晰度"><a href="#6、画面清晰度" class="headerlink" title="6、画面清晰度"></a>6、画面清晰度</h3><p>使用能提高画面锐度的关键词，避免产生模糊的图片。highly detailed和sharp focus是很好的关键词<br>Prompt：a beautiful girl as an enchanting forest elf sitting on a tree, serene expression, wearing a flowing green dress with intricate details, forest dominated by towering trees, sunny, warm sunlight, full body, by Alan Lee, fantasy, hyperrealistic, watercolor, sharp focus, highly detailed, (一个如迷人的森林精灵般的美丽女孩坐在一棵树上，表情安宁，穿着一件带有复杂细节的飘逸绿色连衣裙，参天大树构成的森林，晴天，温暖的阳光，全身像，Alan Lee画的，幻想的，超现实的，水彩，锐利聚焦、高度详细)</p><p><img src="https://img.99shopla.com/jingling6.jpg" alt="jingling6.jpg"></p><h3 id="7、光效"><a href="#7、光效" class="headerlink" title="7、光效"></a>7、光效</h3><p>指定所期望的光线效果，例如侧光、逆光、环境光等，以增强图像的氛围和视觉效果。<br>这里我添加了cinematic lighting（电影灯光）<br>Prompt：a beautiful girl as an enchanting forest elf sitting on a tree, serene expression, wearing a flowing green dress with intricate details, forest dominated by towering trees, sunny, warm sunlight, full body, by Alan Lee, fantasy, hyperrealistic, watercolor, sharp focus, highly detailed, cinematic lighting, high contrast(一个如迷人的森林精灵般的美丽女孩坐在一棵树上，表情安宁，穿着一件带有复杂细节的飘逸绿色连衣裙，参天大树构成的森林，晴天，温暖的阳光，全身像，Alan Lee画的，幻想的，超现实的，水彩，锐利聚焦，高度详细，电影灯光，高对比)</p><p><img src="https://img.99shopla.com/jingling7.jpg" alt="jingling7.jpg"></p><h3 id="8、颜色"><a href="#8、颜色" class="headerlink" title="8、颜色"></a>8、颜色</h3><p>整个画面只有绿色，我觉得有些单调，我还想添加更多颜色进去，比如金色。<br>Prompt：a beautiful girl as an enchanting forest elf sitting on a tree, serene expression, wearing a flowing green dress with intricate details, forest dominated by towering trees, sunny, warm sunlight, full body, by Alan Lee, fantasy, hyperrealistic, watercolor, sharp focus, highly detailed, cinematic lighting, high contrast, radiant gold color vibe, (一个如迷人的森林精灵般的美丽女孩坐在一棵树上，表情安宁，穿着一件带有复杂细节的飘逸绿色连衣裙，参天大树构成的森林，晴天，温暖的阳光，全身像，Alan Lee画的，幻想的，超现实的，水彩，锐利聚焦，高度详细，电影灯光，高对比，闪耀的金黄色颜色氛围)</p><p><img src="https://img.99shopla.com/jingling8.jpg" alt="jingling8.jpg"></p><h3 id="反向关键词"><a href="#反向关键词" class="headerlink" title="反向关键词"></a>反向关键词</h3><p>如果你才刚开始接触AI绘画，还不太懂怎么调整反向关键词，那么就先使用下面这个通用的negative prompt吧<br>negative prompt：ugly, tiling, poorly drawn hands, poorly drawn feet, poorly drawn face, out of frame, extra limbs, disfigured, deformed, body out of frame, bad anatomy, watermark, signature, cut off, low contrast, underexposed, overexposed, bad art, beginner, amateur, distorted face, blurry, draft, grainy<br>后面掌握了反向关键词再自己调整。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>可能你已经注意到，即使我只是使用了很少的关键词，但是生成的图片效果也已经很不错了。<br>所以在写prompt的时候，需要注意，你不需要包含以上所有类别的关键词，你可以挑选其中几种搭配使用。另外，关键词顺序可以自己更换，顺序越靠前，权重越高，就越大概率生成符合该关键词的结果。<br>将关键词分类的意义是方便记忆。当在你需要生成某些特定图片的时候，你就知道应该从哪些方面去限定生成的范围，这样就可以生成更接近你预期的图片。<br>入门之后自己多摸索摸索，keep creative！！！</p>]]></content>
      
      
      <categories>
          
          <category> 免费资源 </category>
          
          <category> 基础教程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AI智能 </tag>
            
            <tag> AI绘画 </tag>
            
            <tag> AI绘图 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[Stable-Diffusion图生图使用]</title>
      <link href="/posts/1861.html"/>
      <url>/posts/1861.html</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="Stable-Diffusion图生图使用"><a href="#Stable-Diffusion图生图使用" class="headerlink" title="[Stable-Diffusion图生图使用]"></a>[Stable-Diffusion图生图使用]</h1><p><img src="https://img.99shopla.com/SDtushengtu.jpg" alt="Stable-Diffusion图生图-2048x1152.jpg"></p><p>1、**&#x3D;&#x3D;操作步骤：&#x3D;&#x3D;<strong>选择 绘画模型（Stable Diffusion checkpoint）→ 选择图生图（img2img）→上传图片 → 填写正向提示词（Prompt） →填写反向提示词（Negative prompt） → 选择采样器（一般选择DPM++ 2M Karras） →设置采样步骤（一般设置28——30） → 设置长宽（Width &#x2F; Height）→点击生成（Generate）（</strong>&#x3D;&#x3D;重绘强度一般选择默认&#x3D;&#x3D;**）</p><p>2、缩放模式：在重绘强度为0的时候，改变图片宽度、高度，能够很直观看到效果</p><ul><li>拉伸：将图片拉伸以适应目标尺寸（通常尺寸变大时使用）</li><li>裁剪：将部分裁剪掉以适应尺寸（尺寸变小时使用）</li><li>填充：重新生成一部分内容填充空白（尺寸变大时），用于风景的图片效果会比较好，人像效果不好</li><li>直接缩放：根据原来的图片风格生成一张全新的图片，测试下来效果不是很好，用得比较少</li></ul><p>3、图生图</p><ul><li>效果：根据提示词和上传的图片生成一张新的图片，**&#x3D;&#x3D;在seed值不变的情况下，我们可以调整采样步数和重绘强&#x3D;&#x3D;**度来重新生成风格较为接近的图片</li></ul><p>4、涂鸦绘制（常用用法换装）</p><ul><li>效果：依据提示词、上传的图片和涂抹部分的颜色重新生成一张图片，被涂抹部分会依据涂抹的颜色来改变，并且会填充风格相似的内容，**&#x3D;&#x3D;在seed值不变的情况下，我们可以调整采样步数和重绘强度来重新生成风格较为接近的图片&#x3D;&#x3D;**</li></ul><p>5、局部绘制（可以用来修改、调整局部）</p><ul><li>效果：只重绘被涂抹部分，不改变原图其他部分，适合用来调整不满意的部分</li></ul><p>6、局部绘制（涂鸦蒙版）</p><ul><li>效果：改变涂抹部分的颜色并重绘涂抹部分，集成了涂鸦绘制和局部绘制（涂鸦蒙版）的功能，重绘部分的颜色会依据涂抹的颜色来改变</li><li>蒙版模糊度&#x2F;Mask blur：蒙版模糊度，在 0-64 之间调节，就是将我们涂抹区域，从边缘向中间透明过渡。数值较小的时候，边缘越锐利，所以一个合适的值会让图片看起来更真实，数值一般默认即可</li><li>蒙版透明度&#x2F;Mask transparency：蒙版的透明度，一般默认为0，即不透明，因为透明度越高，AI发挥的空间越小，同时涂抹部分受蒙版颜色干扰越少，而且生成的图片越接近原图被涂抹部分</li></ul>]]></content>
      
      
      <categories>
          
          <category> 使用教程 </category>
          
          <category> 免费资源 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AI智能 </tag>
            
            <tag> AI绘画 </tag>
            
            <tag> AI绘图 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>style2paints – 最强的线描图画上色工具！不需要安装任何环境、做任何配置，下载然后双击即可！</title>
      <link href="/posts/240a.html"/>
      <url>/posts/240a.html</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="style2paints-–-最强的线描图画上色工具！不需要安装任何环境、做任何配置，下载然后双击即可！"><a href="#style2paints-–-最强的线描图画上色工具！不需要安装任何环境、做任何配置，下载然后双击即可！" class="headerlink" title="style2paints – 最强的线描图画上色工具！不需要安装任何环境、做任何配置，下载然后双击即可！"></a>style2paints – 最强的线描图画上色工具！不需要安装任何环境、做任何配置，下载然后双击即可！</h1><p>Style2paints – 不需要安装任何环境、做任何配置，下载然后双击，就可以给线描图画上色。</p><p>这个 AI 项目是二次元的福音，虽然他是基于 AI 驱动，但这个项目不需要你安装任何环境、做任何配置。直接下载，然后双击，就可以给一个线描图画上色了。</p><p><a href="https://www.freedidi.com/wp-content/uploads/2023/01/freedidi.com_2023-01-24-124200.jpg"><img src="https://www.freedidi.com/wp-content/uploads/2023/01/freedidi.com_2023-01-24-124200.jpg"></a></p><p><strong>1.开源项目：【<a href="https://github.com/lllyasviel/style2paints">Github</a>】</strong></p><p><strong>2.下载地址：【【<a href="https://pan.baidu.com/s/15xCm1jRVeHipHkiB3n1vzA">百度云盘</a>】</strong></p>]]></content>
      
      
      <categories>
          
          <category> 免费资源 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AI智能 </tag>
            
            <tag> AI绘画 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SD WEBUI基础教程（一）</title>
      <link href="/posts/c369.html"/>
      <url>/posts/c369.html</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="sd教程-一劳永逸，免费使用ai绘画的方法，看这里！"><a href="#sd教程-一劳永逸，免费使用ai绘画的方法，看这里！" class="headerlink" title="sd教程| 一劳永逸，免费使用ai绘画的方法，看这里！"></a>sd教程| 一劳永逸，免费使用ai绘画的方法，看这里！</h1><p>如果你很想接触ai绘画，但是又不知道怎么入门，那么看这篇文章就对了！<br>工欲善其事必先利其器， 接下来会详细说说怎么将sdwebui安装到本地。<br>安装到本地之后就可以离线生成图片，不像网上的ai绘图，本地运行的sd没有任何限制！！！意味着你可以生成任何你想要的图片！</p><h2 id="一、什么是stable-diffusion？"><a href="#一、什么是stable-diffusion？" class="headerlink" title="一、什么是stable diffusion？"></a>一、什么是stable diffusion？</h2><p>Stable diffusion（简称sd）是一种文生图AI模型。能够将输入的文字转化为高分辨率的图片。比如，当我输入：1girl, beautiful, realistic（1个女孩，美丽，现实）<br>输出的图片为：</p><p><img src="https://ph.99shopla.com/girl00011.jpg" alt="1个女孩"></p><p>当然，文生图模型除了sd，还有Midjourney和DALL-E，但sd具有显著的优点，让我们乐于选择使用它：</p><ol><li>开源，stable diffusion是一种开源模型，意味着任何人都可以免费试用，而且有很多热衷于AI绘图的大佬参与到后续的开发中，编写了许多非常好用的程序和工具。</li><li>性能要求低，可以在消费级的显卡上运行，显卡内存只需要大于4G。</li><li>本地部署，在电脑安装stable diffusion后可以离线生成图片，DALL-E和Midjourney只能通过云端生成图片，而且对个人来说费用较高。</li></ol><h2 id="三、sd能生成哪些类型的图片？"><a href="#三、sd能生成哪些类型的图片？" class="headerlink" title="三、sd能生成哪些类型的图片？"></a>三、sd能生成哪些类型的图片？</h2><p>稳定扩散模型在生成图片方面的能力可谓无与伦比，其产生的图片类型繁多，几乎囊括所有我们已知类型。从自然景观、动植物，到建筑物、人物肖像，甚至包括抽象艺术和各种奇幻场景，种类之丰富堪称无穷无尽。这种模型的强大功能归功于其先进的算法和大量的训练数据，使得它能够学习各种风格和主题的图特点，并且能够根据提示词进行创新组合，为我们提供无限的艺术灵感源泉。以下是一些例子：</p><a class="btn-beautify outline red larger" href="https://99shopla.com/photo"   title="美图"><i class="far fa-hand-point-right"></i><span>美图</span></a>]]></content>
      
      
      <categories>
          
          <category> 免费资源 </category>
          
          <category> 基础教程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AI绘画 </tag>
            
            <tag> AI画图 </tag>
            
            <tag> 软件 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
